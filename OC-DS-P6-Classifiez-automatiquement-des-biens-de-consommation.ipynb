{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a26ed8ec",
   "metadata": {},
   "source": [
    "# Mise en forme des dossiers de travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bde1967",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python 3.6.13 :: Anaconda, Inc.\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b01ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.getcwd().split('\\\\')[-1]!='OC-DS-P6-Classifiez-automatiquement-des-biens-de-consommation':\n",
    "    # si valeur diff 'C:\\\\Users\\\\...\\\\Projets\\\\P6\\\\OC-DS-P6-Classifiez-automatiquement-des-biens-de-consommation'\n",
    "    os.chdir('OC-DS-P6-Classifiez-automatiquement-des-biens-de-consommation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac61941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_core as tfc\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))#tf.config.list_physical_devices('GPU')\n",
    "print('la version de tensorflow est: ', tf.__version__)\n",
    "print('la version de tensorflow_core est: ', tfc.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555a00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (224,224)\n",
    "train_path = 'data/cleaned/Images/train'\n",
    "test_path  = 'data/cleaned/Images/test'\n",
    "all_path   = 'data/cleaned/Images/all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b91513f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed: Le module spécifié est introuvable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d5423a86056d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMAX_IMAGE_PIXELS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;31m# Also note that Image.core is not a publicly documented interface,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;31m# and should be considered private and subject to change.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_imaging\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"PILLOW_VERSION\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: Le module spécifié est introuvable."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "if not os.path.exists( train_path ): \n",
    "    os.makedirs( train_path )\n",
    "    \n",
    "if not os.path.exists( test_path ): \n",
    "    os.makedirs( test_path )\n",
    "\n",
    "for repertoire in df.cat_1.unique():\n",
    "    \n",
    "    Xdf = df.loc[df.cat_1==repertoire]\n",
    "    #print(df.iloc[i][['cat_1']].values[0])\n",
    "    \n",
    "    # Create the repositorys only if it doesn't existe yet\n",
    "    for t in [train_path, test_path,all_path]:\n",
    "\n",
    "        if not os.path.exists( t+\"_\".join(repertoire.split(' ')) ): \n",
    "            os.makedirs( t+\"_\".join(repertoire.split(' ')) )\n",
    "    \n",
    "    # create train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split( Xdf[['image']], Xdf[['cat_1']], test_size=0.33, random_state=42)\n",
    "    \n",
    "    # resize and write .jpg train files\n",
    "    for img in X_train.values:  \n",
    "        image = Image.open('data/source/raw_folder_image/'+img[0]) \n",
    "\n",
    "        # Resizing image\n",
    "        new_image = image.resize((224, 224))\n",
    "\n",
    "        # Sauvegarde image format JPEG\n",
    "        new_image.save(train_path+'/'+\"_\".join(repertoire.split(' '))+'/'+img[0],format = 'JPEG')\n",
    "    \n",
    "    # resize and write .jpg test files\n",
    "    for img in X_test.values:  \n",
    "        image = Image.open('data/source/raw_folder_image/'+img[0]) \n",
    "\n",
    "        # Resizing image\n",
    "        new_image = image.resize((224, 224))\n",
    "\n",
    "        # Sauvegarde image format JPEG\n",
    "        new_image.save(test_path+'/'+\"_\".join(repertoire.split(' '))+'/'+img[0],format = 'JPEG')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2e72d3",
   "metadata": {},
   "source": [
    "## Utilisation du VGG-16 pré-entraîné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b77174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 32s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "model = VGG16() # Création du modèle VGG-16 implementé par Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d948492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "img = load_img('cat.jpg', target_size=(224, 224))  # Charger l'image\n",
    "img = img_to_array(img)  # Convertir en tableau numpy\n",
    "img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))  # Créer la collection d'images (un seul échantillon)\n",
    "img = preprocess_input(img)  # Prétraiter l'image comme le veut VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdda84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.predict(img)  # Prédir la classe de l'image (parmi les 1000 classes d'ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c689e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "# Afficher les 3 classes les plus probables\n",
    "print('Top 3 :', decode_predictions(y, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d87d2",
   "metadata": {},
   "source": [
    "## Transfert Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e723e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras import Model\n",
    "# Charger VGG-16 pré-entraîné sur ImageNet et sans les couches fully-connected\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "296c4975",
   "metadata": {},
   "source": [
    "Lors du chargement d'un modèle donné, l'argument « include_top » peut être défini sur False , auquel cas les couches de sortie entièrement connectées du modèle utilisé pour faire des prédictions ne sont pas chargées, ce qui permet d'ajouter et de former une nouvelle couche de sortie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01d03f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VGG16(weights=\"imagenet\", input_shape=(224, 224, 3)).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32871e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d609c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob2\n",
    "train_folders = glob2(train_path+'/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605aa0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer la sortie de ce réseau et ajout d'une couche de Flatten \n",
    "x = Flatten()(model.output)\n",
    "\n",
    "# Ajouter la nouvelle couche fully-connected pour la classification à 7 classes\n",
    "predictions = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# Définir le nouveau modèle\n",
    "new_model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6edf956",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be0049",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "   layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bc241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne pas entraîner les 5 premières couches (les plus basses) \n",
    "for layer in model.layers[:5]:\n",
    "   layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ea64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle \n",
    "new_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# Entraîner sur les données d'entraînement (X_train, y_train)\n",
    "model_info = new_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
