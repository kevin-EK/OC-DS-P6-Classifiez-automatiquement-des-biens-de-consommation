{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La version de tensorflow utilisé est: 2.1.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import os\n",
    "from os import listdir\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score, roc_curve\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalAveragePooling1D, Flatten, Dense, Dropout, experimental \n",
    "#from tensorflow.keras.layers import Rescaling, RandomFlip, RandomRotation, RandomZoom\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# os.environ[\"TF_KERAS\"]='1'\n",
    "print(\"La version de tensorflow utilisé est:\",tf.version.VERSION)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>image</th>\n",
       "      <th>description</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>cat_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7</td>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7.jpg</td>\n",
       "      <td>Key Features of Elegance Polyester Multicolor ...</td>\n",
       "      <td>['key', 'feature', 'elegance', 'polyester', 'm...</td>\n",
       "      <td>home furnishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590</td>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590.jpg</td>\n",
       "      <td>Specifications of Sathiyas Cotton Bath Towel (...</td>\n",
       "      <td>['specification', 'sathiyas', 'cotton', 'bath'...</td>\n",
       "      <td>baby care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74</td>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74.jpg</td>\n",
       "      <td>Key Features of Eurospa Cotton Terry Face Towe...</td>\n",
       "      <td>['key', 'feature', 'eurospa', 'cotton', 'terry...</td>\n",
       "      <td>baby care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4684dcdc759dd9cdf41504698d737d8</td>\n",
       "      <td>d4684dcdc759dd9cdf41504698d737d8.jpg</td>\n",
       "      <td>Key Features of SANTOSH ROYAL FASHION Cotton P...</td>\n",
       "      <td>['key', 'feature', 'santosh', 'royal', 'fashio...</td>\n",
       "      <td>home furnishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6325b6870c54cd47be6ebfbffa620ec7</td>\n",
       "      <td>6325b6870c54cd47be6ebfbffa620ec7.jpg</td>\n",
       "      <td>Key Features of Jaipur Print Cotton Floral Kin...</td>\n",
       "      <td>['key', 'feature', 'jaipur', 'print', 'cotton'...</td>\n",
       "      <td>home furnishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            uniq_id  ...            cat_1\n",
       "0  55b85ea15a1536d46b7190ad6fff8ce7  ...  home furnishing\n",
       "1  7b72c92c2f6c40268628ec5f14c6d590  ...        baby care\n",
       "2  64d5d4a258243731dc7bbb1eef49ad74  ...        baby care\n",
       "3  d4684dcdc759dd9cdf41504698d737d8  ...  home furnishing\n",
       "4  6325b6870c54cd47be6ebfbffa620ec7  ...  home furnishing\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cleaned/description_cleaned_spacy.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "train_path = 'data/cleaned/Images/train/'\n",
    "test_path = 'data/cleaned/Images/test/'\n",
    "\n",
    "df = pd.read_csv('data/cleaned/description_cleaned_spacy.csv')\n",
    "\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "\n",
    "if not os.path.exists( train_path ): \n",
    "    os.makedirs( train_path )\n",
    "    \n",
    "if not os.path.exists( test_path ): \n",
    "    os.makedirs( test_path )\n",
    "\n",
    "for repertoire in df.cat_1.unique():\n",
    "    \n",
    "    Xdf = df.loc[df.cat_1==repertoire]\n",
    "    #print(df.iloc[i][['cat_1']].values[0])\n",
    "    \n",
    "    # Create the repositorys only if it doesn't existe yet\n",
    "    for t in [train_path, test_path]:\n",
    "\n",
    "        if not os.path.exists( t+'/'+\"_\".join(repertoire.split(' ')) ): \n",
    "            os.makedirs( t+'/'+\"_\".join(repertoire.split(' ')) )\n",
    "    \n",
    "    # create train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split( Xdf[['image']], Xdf[['cat_1']], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # resize and write .jpg train files\n",
    "    for img in X_train.values:  \n",
    "        image = Image.open('data/source/raw_folder_image/'+img[0]) \n",
    "\n",
    "        # Resizing image\n",
    "        new_image = image.resize((224, 224))\n",
    "\n",
    "        # Sauvegarde image format JPEG\n",
    "        new_image.save(train_path+'/'+\"_\".join(repertoire.split(' '))+'/'+img[0],format = 'JPEG')\n",
    "    \n",
    "    # resize and write .jpg test files\n",
    "    for img in X_test.values:  \n",
    "        image = Image.open('data/source/raw_folder_image/'+img[0]) \n",
    "\n",
    "        # Resizing image\n",
    "        new_image = image.resize((224, 224))\n",
    "\n",
    "        # Sauvegarde image format JPEG\n",
    "        new_image.save(test_path+'/'+\"_\".join(repertoire.split(' '))+'/'+img[0],format = 'JPEG')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "IMAGE_SIZE = (224,224)\n",
    "batch_size = 32\n",
    "epochs = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55b85ea15a1536d46b7190ad6fff8ce7.jpg</td>\n",
       "      <td>home furnishing</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b72c92c2f6c40268628ec5f14c6d590.jpg</td>\n",
       "      <td>baby care</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64d5d4a258243731dc7bbb1eef49ad74.jpg</td>\n",
       "      <td>baby care</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d4684dcdc759dd9cdf41504698d737d8.jpg</td>\n",
       "      <td>home furnishing</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6325b6870c54cd47be6ebfbffa620ec7.jpg</td>\n",
       "      <td>home furnishing</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>958f54f4c46b53c8a0a9b8167d9140bc.jpg</td>\n",
       "      <td>baby care</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>fd6cbcc22efb6b761bd564c28928483c.jpg</td>\n",
       "      <td>baby care</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>5912e037d12774bb73a2048f35a00009.jpg</td>\n",
       "      <td>baby care</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>c3edc504d1b4f0ba6224fa53a43a7ad6.jpg</td>\n",
       "      <td>baby care</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>f2f027ad6a6df617c9f125173da71e44.jpg</td>\n",
       "      <td>baby care</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1050 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image       label_name  label\n",
       "0     55b85ea15a1536d46b7190ad6fff8ce7.jpg  home furnishing      4\n",
       "1     7b72c92c2f6c40268628ec5f14c6d590.jpg        baby care      0\n",
       "2     64d5d4a258243731dc7bbb1eef49ad74.jpg        baby care      0\n",
       "3     d4684dcdc759dd9cdf41504698d737d8.jpg  home furnishing      4\n",
       "4     6325b6870c54cd47be6ebfbffa620ec7.jpg  home furnishing      4\n",
       "...                                    ...              ...    ...\n",
       "1045  958f54f4c46b53c8a0a9b8167d9140bc.jpg        baby care      0\n",
       "1046  fd6cbcc22efb6b761bd564c28928483c.jpg        baby care      0\n",
       "1047  5912e037d12774bb73a2048f35a00009.jpg        baby care      0\n",
       "1048  c3edc504d1b4f0ba6224fa53a43a7ad6.jpg        baby care      0\n",
       "1049  f2f027ad6a6df617c9f125173da71e44.jpg        baby care      0\n",
       "\n",
       "[1050 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "from sklearn import preprocessing\n",
    "\n",
    "try:\n",
    "    with open('data/cleaned/description_cleaned_spacy.pkl', 'rb') as f1:\n",
    "        data = pickle.load(f1)\n",
    "except:\n",
    "    data = pd.read_csv('data/cleaned/description_cleaned_spacy.csv')\n",
    "\n",
    "data = data[['image','cat_1']].rename(columns={\"cat_1\": \"label_name\"})\n",
    "\n",
    "# Definir la liste des catégories\n",
    "le = preprocessing.LabelEncoder()\n",
    "data[\"label\"] = le.fit_transform(data[\"label_name\"])\n",
    "\n",
    "# Récuperer la liste des libellé des catégories\n",
    "list_labels = data.label_name.unique()\n",
    "\n",
    "# Definir le nombre de catégories\n",
    "NBCLASS_ = len(data.label_name.unique())\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recuprer la liste de path des train et test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "path_train = 'data/cleaned/Images/train/'\n",
    "path_test = 'data/cleaned/Images/test/'\n",
    "\n",
    "data_train_path = glob(path_train+'*/*.jp*')\n",
    "data_test_path = glob(path_test+'*/*.jp*')\n",
    "\n",
    "def data_fct(path) :\n",
    "    data = pd.DataFrame()\n",
    "    data[\"image_path\"] = path\n",
    "    data[\"image_path\"] = data[\"image_path\"].str.replace('\\\\','/') #transforme les \\\\ en /\n",
    "    data[\"label_name\"] = data[\"image_path\"].str.split('/',expand=True)[4] #\n",
    "    return data\n",
    "\n",
    "data_train = data_fct(data_train_path)\n",
    "data_test = data_fct(data_test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>data/cleaned/Images/train/Home_Decor_&amp;_Festive...</td>\n",
       "      <td>Home_Decor_&amp;_Festive_Needs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>data/cleaned/Images/train/Beauty_and_Personal_...</td>\n",
       "      <td>Beauty_and_Personal_Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>data/cleaned/Images/train/Kitchen_&amp;_Dining/0c7...</td>\n",
       "      <td>Kitchen_&amp;_Dining</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>data/cleaned/Images/train/Watches/8748b6cd9f03...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>data/cleaned/Images/train/Beauty_and_Personal_...</td>\n",
       "      <td>Beauty_and_Personal_Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>data/cleaned/Images/train/Kitchen_&amp;_Dining/503...</td>\n",
       "      <td>Kitchen_&amp;_Dining</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>data/cleaned/Images/train/Beauty_and_Personal_...</td>\n",
       "      <td>Beauty_and_Personal_Care</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>data/cleaned/Images/train/Home_Decor_&amp;_Festive...</td>\n",
       "      <td>Home_Decor_&amp;_Festive_Needs</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>data/cleaned/Images/train/Computers/6e7cc21610...</td>\n",
       "      <td>Computers</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>data/cleaned/Images/train/Watches/700dfd088162...</td>\n",
       "      <td>Watches</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_path                  label_name  label\n",
       "360  data/cleaned/Images/train/Home_Decor_&_Festive...  Home_Decor_&_Festive_Needs    NaN\n",
       "119  data/cleaned/Images/train/Beauty_and_Personal_...    Beauty_and_Personal_Care    NaN\n",
       "507  data/cleaned/Images/train/Kitchen_&_Dining/0c7...            Kitchen_&_Dining    NaN\n",
       "654  data/cleaned/Images/train/Watches/8748b6cd9f03...                     Watches    NaN\n",
       "132  data/cleaned/Images/train/Beauty_and_Personal_...    Beauty_and_Personal_Care    NaN\n",
       "530  data/cleaned/Images/train/Kitchen_&_Dining/503...            Kitchen_&_Dining    NaN\n",
       "150  data/cleaned/Images/train/Beauty_and_Personal_...    Beauty_and_Personal_Care    NaN\n",
       "366  data/cleaned/Images/train/Home_Decor_&_Festive...  Home_Decor_&_Festive_Needs    NaN\n",
       "239  data/cleaned/Images/train/Computers/6e7cc21610...                   Computers    NaN\n",
       "644  data/cleaned/Images/train/Watches/700dfd088162...                     Watches    NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['label'] = data_train.label_name.map({'baby_care':0, 'beauty_and_personal_care':1, 'computers':2,\n",
    "       'home_decor_&_festive_needs':3, 'home_furnishing':4, 'kitchen_&_dining':5, 'watches':6})\n",
    "\n",
    "data_test['label'] = data_test.label_name.map({'baby_care':0, 'beauty_and_personal_care':1, 'computers':2,\n",
    "       'home_decor_&_festive_needs':3, 'home_furnishing':4, 'kitchen_&_dining':5, 'watches':6})\n",
    "\n",
    "data_train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Home_Decor_&_Festive_Needs    50\n",
       "Watches                       50\n",
       "Baby_Care                     50\n",
       "Kitchen_&_Dining              50\n",
       "Home_Furnishing               50\n",
       "Computers                     50\n",
       "Beauty_and_Personal_Care      50\n",
       "Name: label_name, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.label_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image  label_name\n",
       "label                   \n",
       "0        150         150\n",
       "1        150         150\n",
       "2        150         150\n",
       "3        150         150\n",
       "4        150         150\n",
       "5        150         150\n",
       "6        150         150"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 1 : étude de faisabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle pré-entraîné"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Mul] name: fc1/kernel/Initializer/random_uniform/mul/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-0744571b7156>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbase_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'utils'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\applications\\vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\keras_applications\\vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;31m# Classification block\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'flatten'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fc1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fc2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    746\u001b[0m           \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    749\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2114\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2115\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2116\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2117\u001b[0m       \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2118\u001b[0m       \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1113\u001b[1;33m         trainable=True)\n\u001b[0m\u001b[0;32m   1114\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1115\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         caching_device=caching_device)\n\u001b[0m\u001b[0;32m    447\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         **kwargs_for_getter)\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    140\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         shape=shape)\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m                         shape=None):\n\u001b[0;32m    196\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2594\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2596\u001b[1;33m         shape=shape)\n\u001b[0m\u001b[0;32m   2597\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2598\u001b[0m     return variables.RefVariable(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1409\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1411\u001b[1;33m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[0;32m   1412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m   def _init_from_args(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1540\u001b[0m           \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initializer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1541\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[1;32m-> 1542\u001b[1;33m                 \u001b[0minitial_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1543\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[0;32m   1544\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    120\u001b[0m           (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[0;32m    121\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m       \u001b[0minit_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m       \u001b[0mvariable_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype)\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m    786\u001b[0m       \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m     return op(\n\u001b[1;32m--> 788\u001b[1;33m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[0mrnd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_random_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnd\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m     \u001b[1;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 902\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    903\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1199\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1200\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1201\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1202\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6120\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6121\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6122\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6123\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6124\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6605\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6606\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6607\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py36_tensorflow\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Mul] name: fc1/kernel/Initializer/random_uniform/mul/"
     ]
    }
   ],
   "source": [
    "base_model = VGG16()\n",
    "model = Model(inputs=base_model.inputs, outputs=base_model.layers[-2].output)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création des features des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T13:11:24.767685Z",
     "start_time": "2020-12-31T13:09:49.843465Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_features = []\n",
    "i=0 \n",
    "for image_file in data[\"image\"] :\n",
    "    if i%100 == 0 : print(i)\n",
    "    i +=1\n",
    "    image = load_img('data/source/raw_folder_image/'+image_file, target_size=(224, 224))\n",
    "    image = img_to_array(image) \n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = preprocess_input(image)\n",
    "    images_features.append(model.predict(image, verbose=0)[0]) # predict from pretrained model\n",
    "\n",
    "images_features = np.asarray(images_features)\n",
    "images_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réduction dimension et analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réduction de dimension PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold, decomposition\n",
    "\n",
    "print(images_features.shape)\n",
    "pca = decomposition.PCA(n_components=0.99)\n",
    "feat_pca= pca.fit_transform(images_features)\n",
    "print(feat_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réduction de dimension T-SNE et affichage des images selon vraies classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold, decomposition\n",
    "import time\n",
    "\n",
    "temps1 = time.time()\n",
    "\n",
    "tsne = manifold.TSNE(n_components=2, perplexity=50, n_iter=2000, init='random', random_state=6)\n",
    "X_tsne = tsne.fit_transform(feat_pca)\n",
    "\n",
    "duration1=time.time()-temps1\n",
    "print(\"temps de T-SNE : \", \"%15.2f\" % duration1, \"secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tsne = pd.DataFrame(X_tsne, columns=['tsne1', 'tsne2'])\n",
    "df_tsne[\"class\"] = data[\"label_name\"]\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\",\n",
    "    hue=\"class\",\n",
    "    palette=sns.color_palette('tab10', n_colors= NBCLASS_), s=50, alpha=0.6,\n",
    "    data=df_tsne,\n",
    "    legend=\"brief\"\n",
    ")\n",
    "\n",
    "plt.title('TSNE selon les vraies classes', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* L'analyse graphique montre visuellement qu'il est réalisable de séparer automatiquement les images selon leurs vraies classes\n",
    "* Ceci suffit à démontrer la faisabilité de réaliser ultérieurement une classification supervisée pour déterminer automatiquement les classes des images\n",
    "* Cette étape 1 est très rapide à mettre en oeuvre. Une conclusion négative sur la faisabilité aurait éviter de réaliser des traitements beaucoup plus lourd de classification supervisée\n",
    "* Cette démarche en 2 étapes (1. Faisabilité, 2. Classification supervisée si étape 1 OK) s'inscrit dans une démarche agile de tout projet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de clusters à partir du T-SNE et affichage des images selon clusters\n",
    "* Attention : ici, il ne s'agit pas de faire une classification non supervisée, mais simplement, par une mesure de l'ARI, de conforter l'analyse graphique précédente qui démontre la faisabilité de réaliser ultérieurement une classification supervisée. Cette mesure de l'ARI nécessite de créer des clusters théoriques via KMeans\n",
    "* Il s'agit donc de réaliser une mesure de ce que nous voyons graphiquement, donc à partir des données en sortie du t-sne\n",
    "* Pour réaliser une classification non supervisée, il aurait fallu repartir des données avant t-sne\n",
    "* Dans la démarche en 2 étapes, il n'est pas utile de réaliser une classification non supervisée, une classification supervisée est bien plus performante. Même le calcul de l'ARI n'est pas indispensable, nous pourrions passer directement du graphique t-sne précédent à l'étape 2 de classification supervisée\n",
    "* Il n'est donc pas utile de passer du temps à optimiser l'ARI, un ordre de grandeur suffit pour conforter le 1er graphique t-sne. D'ailleurs la meilleure solution de feature engineering ne génère pas toujours le meilleur ARI. L'analyse graphique t-sne est bien plus riche d'enseignement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cluster, metrics\n",
    "\n",
    "cls = cluster.KMeans(n_clusters= NBCLASS_ , n_init=100)\n",
    "cls.fit(X_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_tsne[\"cluster\"] = cls.labels_\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.scatterplot(\n",
    "    x=\"tsne1\", y=\"tsne2\",\n",
    "    hue=\"cluster\",\n",
    "    palette=sns.color_palette('tab10', n_colors= NBCLASS_ ), s=50, alpha=0.6,\n",
    "    data=df_tsne,\n",
    "    legend=\"brief\")\n",
    "\n",
    "plt.title('TSNE selon les clusters', fontsize = 30, pad = 35, fontweight = 'bold')\n",
    "plt.xlabel('tsne1', fontsize = 26, fontweight = 'bold')\n",
    "plt.ylabel('tsne2', fontsize = 26, fontweight = 'bold')\n",
    "plt.legend(prop={'size': 14}) \n",
    "\n",
    "plt.show()\n",
    "\n",
    "labels = data[\"label\"]\n",
    "print(\"ARI : \", metrics.adjusted_rand_score(labels, cls.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Analyse : le modèle pré-entraîné confond \"cloud\" avec de la neige ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse par classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = metrics.confusion_matrix(data.label, cls.labels_)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_mat_transform(y_true,y_pred) :\n",
    "    conf_mat = metrics.confusion_matrix(y_true,y_pred)\n",
    "    \n",
    "    corresp = np.argmax(conf_mat, axis=0)\n",
    "    print (\"Correspondance des clusters : \", corresp)\n",
    "    # y_pred_transform = np.apply_along_axis(correspond_fct, 1, y_pred)\n",
    "    labels = pd.Series(y_true, name=\"y_true\").to_frame()\n",
    "    labels['y_pred'] = y_pred\n",
    "    labels['y_pred_transform'] = labels['y_pred'].apply(lambda x : corresp[x]) \n",
    "    \n",
    "    return labels['y_pred_transform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_labels_transform = conf_mat_transform(labels, cls.labels_)\n",
    "conf_mat = metrics.confusion_matrix(labels, cls_labels_transform)\n",
    "print(conf_mat)\n",
    "print()\n",
    "print(metrics.classification_report(labels, cls_labels_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(conf_mat, index = [label for label in data.label_name.unique()],\n",
    "                  columns = [i for i in \"0123456\"])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5), tight_layout=True,sharey=True)\n",
    "sns.heatmap(df_cm, annot=True,fmt='d', cmap=\"Blues\",ax= ax1)\n",
    "sns.heatmap(df_cm.apply(lambda x:x/x.sum(),axis=1), annot=True,fmt='.2%', cmap=\"Blues\",ax= ax2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La classe la moins bien prédite est \"kitchen & dining\" (CF exemple ci-dessus : confond la neige avec un nuage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etape 2 : classification supervisée\n",
    "4 approches sont présentées :\n",
    "* Une approche simple par préparation initiale de l'ensemble des images avant classification supervisée\n",
    "* Une approche par data generator, permettant facilement la data augmentation. Les images sont directement récupérées à la volée dans le repertoire des images\n",
    "* Une approche récente proposée par Tensorflow.org par DataSet, sans data augmentation\n",
    "* Une approche par  DataSet, avec data augmentation intégrée au modèle : layer en début de modèle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model_fct() :\n",
    "    # Récupération modèle pré-entraîné\n",
    "    model0 = VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "\n",
    "    # Layer non entraînables = on garde les poids du modèle pré-entraîné\n",
    "    for layer in model0.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Récupérer la sortie de ce réseau\n",
    "    x = model0.output\n",
    "    # Compléter le modèle\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(NBCLASS_, activation='softmax')(x)\n",
    "\n",
    "    # Définir le nouveau modèle\n",
    "    model = Model(inputs=model0.input, outputs=predictions)\n",
    "    # compilation du modèle \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer= 'adam',#'rmsprop', \n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche préparation initiale des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_prep_fct(data) :\n",
    "    prepared_images = []\n",
    "    for image_num in range(len(data['image_path'])) :\n",
    "        img = (load_img(\n",
    "            data['image_path'][image_num],\n",
    "            target_size=(224, 224)))\n",
    "        img = img_to_array(img)\n",
    "        img = img.reshape((img.shape[0], img.shape[1], img.shape[2]))\n",
    "        img = preprocess_input(img)\n",
    "        prepared_images.append(img)\n",
    "        prepared_images_np = np.array(prepared_images)\n",
    "    return prepared_images_np\n",
    "    \n",
    "images_np_train = image_prep_fct(data_train)\n",
    "print(images_np_train.shape)\n",
    "images_np_test = image_prep_fct(data_test)\n",
    "print(images_np_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = images_np_train\n",
    "y = to_categorical(data_train['label'])\n",
    "\n",
    "X_test = images_np_test\n",
    "y_test = to_categorical(data_test['label'])\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.25, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Création du modèle\n",
    "with tf.device('/gpu:0'): \n",
    "    model1 = create_model_fct()\n",
    "\n",
    "# Création du callback\n",
    "model1_save_path1 = \"./model1_best_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(model1_save_path1, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "callbacks_list = [checkpoint, es]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Entraîner sur les données d'entraînement (X_train, y_train)\n",
    "with tf.device('/gpu:0'): \n",
    "    history1 = model1.fit(X_train, y_train, epochs=50, batch_size=64, \n",
    "                       callbacks=callbacks_list, validation_data=(X_val, y_val), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Score du dernier epoch\n",
    "\n",
    "loss, accuracy = model1.evaluate(X_train, y_train, verbose=True)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "print()\n",
    "loss, accuracy = model1.evaluate(X_val, y_val, verbose=True)\n",
    "print(\"Validation Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score de l'epoch optimal\n",
    "\n",
    "model1.load_weights(model1_save_path1)\n",
    "\n",
    "loss, accuracy = model1.evaluate(X_val, y_val, verbose=False)\n",
    "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))\n",
    "\n",
    "loss, accuracy = model1.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Test Accuracy       :  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from plot_keras_history import show_history, plot_history\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    show_history(history1)\n",
    "    plot_history(history1, path=\"standard.png\")\n",
    "    plt.close()\n",
    "except:\n",
    "    epochs_range = range(11)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, history1.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(epochs_range, history1.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, history1.history['loss'], label='Training Loss')\n",
    "    plt.plot(epochs_range, history1.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_val_num = np.argmax(y_val, axis=1)\n",
    "y_val_pred = np.argmax(model1.predict(X_val), axis=1)\n",
    "y_val_num = np.argmax(y_val, axis=1)\n",
    "print(y_val_num)\n",
    "print()\n",
    "print(y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = metrics.confusion_matrix(y_val_num, y_val_pred)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred_transform = conf_mat_transform(y_val_num, y_val_pred)\n",
    "conf_mat = metrics.confusion_matrix(y_val_num, y_val_pred_transform)\n",
    "print(conf_mat)\n",
    "print()\n",
    "print(metrics.classification_report(y_val_num, y_val_pred_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm = pd.DataFrame(conf_mat, index = [label for label in list_labels],\n",
    "                  columns = [i for i in \"0123456\"])\n",
    "plt.figure(figsize = (6,4))\n",
    "sns.heatmap(df_cm, annot=True, cmap=\"Blues\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</Br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche ImageDatagenerator avec data augmentation\n",
    "\n",
    "CF https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow (noté désormais comme \"deprecated\", incite à utiiser l'approche suivante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour mélanger les images, classées initalement par classe\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "def data_flow_fct(data, datagen, data_type=None) :\n",
    "    data_flow = datagen.flow_from_dataframe(data, directory='',\n",
    "                                x_col='image_path', y_col='label_name',\n",
    "                                weight_col=None, target_size=(224, 224),\n",
    "                                classes=None, class_mode='categorical',\n",
    "                                batch_size=batch_size, shuffle=True, seed=42,\n",
    "                                subset=data_type\n",
    "                                )\n",
    "    return data_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datagen_train = ImageDataGenerator(\n",
    "#    featurewise_center=True,\n",
    "#    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.25,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "train_flow = data_flow_fct(data_train, datagen_train, data_type='training')\n",
    "val_flow = data_flow_fct(data_train, datagen_train, data_type='validation')\n",
    "\n",
    "datagen_test = ImageDataGenerator(\n",
    "    validation_split=0,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "test_flow = data_flow_fct(data_test, datagen_test, data_type=None)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "# datagen.fit(X_train)\n",
    "# fits the model on batches with real-time data augmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "with tf.device('/gpu:0'): \n",
    "    model2 = create_model_fct()\n",
    "\n",
    "# Création du callback\n",
    "model2_save_path = \"./model2_best_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(model2_save_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "callbacks_list = [checkpoint, es]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'): \n",
    "    history2 = model2.fit(train_flow,\n",
    "                    validation_data=val_flow,\n",
    "                    batch_size=batch_size, epochs=50, callbacks=callbacks_list, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Score du dernier epoch\n",
    "\n",
    "loss, accuracy = model2.evaluate(train_flow, verbose=True)\n",
    "print(\"Training Accuracy   : {:.4f}\".format(accuracy))\n",
    "print()\n",
    "loss, accuracy = model2.evaluate(val_flow, verbose=True)\n",
    "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score de l'epoch optimal\n",
    "\n",
    "model2.load_weights(model2_save_path)\n",
    "\n",
    "loss, accuracy = model2.evaluate(val_flow, verbose=False)\n",
    "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))\n",
    "\n",
    "loss, accuracy = model2.evaluate(test_flow, verbose=False)\n",
    "print(\"Test Accuracy       :  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from plot_keras_history import show_history, plot_history\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    show_history(history2)\n",
    "    plot_history(history2, path=\"standard.png\")\n",
    "    plt.close()\n",
    "except:\n",
    "    epochs_range = range(len(history2.history['loss']))\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, history2.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(epochs_range, history2.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, history2.history['loss'], label='Training Loss')\n",
    "    plt.plot(epochs_range, history2.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_num = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(model2.predict(X_test), axis=1)\n",
    "y_test_num = np.argmax(y_test, axis=1)\n",
    "print(y_test_num)\n",
    "print()\n",
    "print(y_test_pred)\n",
    "\n",
    "y_test_pred_transform = conf_mat_transform(y_test_num, y_test_pred)\n",
    "conf_mat = metrics.confusion_matrix(y_test_num, y_test_pred_transform)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=list_labels)\n",
    "disp.plot()\n",
    "plt.rcParams['figure.figsize']=[6,6]\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test_num, y_test_pred_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche nouvelle par Dataset sans data augmentation\n",
    "\n",
    "CF https://www.tensorflow.org/tutorials/load_data/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "try:\n",
    "    def dataset_fct(path, validation_split=0, data_type=None) :\n",
    "        dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "                        path, labels='inferred', label_mode='categorical',\n",
    "                        class_names=None, batch_size=32, image_size=(224, 224), shuffle=True, seed=42,\n",
    "                        validation_split=validation_split, subset=data_type\n",
    "                        )\n",
    "        return dataset\n",
    "    \n",
    "    # test de la création de la fonction\n",
    "    dataset_fct(path_train, validation_split=0.25, data_type='training')\n",
    "    \n",
    "except:\n",
    "    def dataset_fct(path, validation_split=0, data_type=None) :\n",
    "        dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                        path, labels='inferred', label_mode='categorical',\n",
    "                        class_names=None, batch_size=32, image_size=(224, 224), shuffle=True, seed=42,\n",
    "                        validation_split=validation_split, subset=data_type\n",
    "                        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_fct(path_train, validation_split=0.25, data_type='training')\n",
    "dataset_val = dataset_fct(path_train, validation_split=0.25, data_type='validation')\n",
    "dataset_test = dataset_fct(path_test, validation_split=0, data_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "with tf.device('/gpu:0'): \n",
    "    model3 = create_model_fct()\n",
    "\n",
    "# Création du callback\n",
    "model3_save_path = \"./model3_best_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(model3_save_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "callbacks_list = [checkpoint, es]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'): \n",
    "    history3 = model3.fit(dataset_train,\n",
    "                    validation_data=dataset_val,\n",
    "                    batch_size=batch_size, epochs=50, callbacks=callbacks_list, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Score du dernier epoch\n",
    "\n",
    "loss, accuracy = model3.evaluate(dataset_train, verbose=True)\n",
    "print(\"Training Accuracy   : {:.4f}\".format(accuracy))\n",
    "print()\n",
    "loss, accuracy = model3.evaluate(dataset_val, verbose=True)\n",
    "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score de l'epoch optimal\n",
    "\n",
    "model3.load_weights(model3_save_path)\n",
    "\n",
    "loss, accuracy = model3.evaluate(dataset_val, verbose=False)\n",
    "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))\n",
    "\n",
    "loss, accuracy = model3.evaluate(dataset_test, verbose=False)\n",
    "print(\"Test Accuracy       :  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from plot_keras_history import show_history, plot_history\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    show_history(history3)\n",
    "    plot_history(history3, path=\"standard.png\")\n",
    "    plt.close()\n",
    "except:\n",
    "    epochs_range = range(len(history3.history['loss']))\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, history3.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(epochs_range, history3.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, history3.history['loss'], label='Training Loss')\n",
    "    plt.plot(epochs_range, history3.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(model3.predict(X_test), axis=1)\n",
    "\n",
    "y_test_pred_transform = conf_mat_transform(y_test_num, y_test_pred)\n",
    "conf_mat = metrics.confusion_matrix(y_test_num, y_test_pred_transform)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=list_labels)\n",
    "disp.plot()\n",
    "plt.rcParams['figure.figsize']=[6,6]\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test_num, y_test_pred_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche nouvelle par Dataset avec data augmentation intégrée au modèle\n",
    "\n",
    "CF https://www.tensorflow.org/tutorials/images/data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "try:\n",
    "    def dataset_fct(path, validation_split=0, data_type=None) :\n",
    "        dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "                        path, labels='inferred', label_mode='categorical',\n",
    "                        class_names=None, batch_size=batch_size, image_size=(224, 224), shuffle=True, seed=42,\n",
    "                        validation_split=validation_split, subset=data_type\n",
    "                        )\n",
    "        return dataset\n",
    "    \n",
    "    # test de la création de la fonction\n",
    "    dataset_fct(path_train, validation_split=0.25, data_type='training')\n",
    "    \n",
    "except:\n",
    "    def dataset_fct(path, validation_split=0, data_type=None) :\n",
    "        dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                        path, labels='inferred', label_mode='categorical',\n",
    "                        class_names=None, batch_size=batch_size, image_size=(224, 224), shuffle=True, seed=42,\n",
    "                        validation_split=validation_split, subset=data_type\n",
    "                        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_fct(path_train, validation_split=0.25, data_type='training')\n",
    "dataset_val = dataset_fct(path_train, validation_split=0.25, data_type='validation')\n",
    "dataset_test = dataset_fct(path_test, validation_split=0, data_type=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_rescale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = (image / 255.0)\n",
    "    return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "test_spec = importlib.util.find_spec(\"tensorflow.keras.layers.RandomFlip\")\n",
    "test_spec is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_fct2() :\n",
    "    import importlib.util\n",
    "    test_spec = importlib.util.find_spec(\"tensorflow.keras.layers.RandomFlip\")\n",
    "    \n",
    "    if test_spec is not None:\n",
    "        # Data augmentation\n",
    "        data_augmentation = Sequential([\n",
    "            tf.keras.layers.RandomFlip(\"horizontal\", input_shape=(224, 224, 3)), #A preprocessing layer which randomly flips images during training.\n",
    "            tf.keras.layers.RandomRotation(0.1), #A preprocessing layer which randomly rotates images during training.\n",
    "            tf.keras.layers.RandomZoom(0.1), # A preprocessing layer which randomly zooms images during training\n",
    "            # tf.keras.layers.Rescaling(1./127.5, offset=-1.0)\n",
    "          ])\n",
    "        \n",
    "        # Récupération modèle pré-entraîné\n",
    "        model_base = VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "        for layer in model_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Définition du nouveau modèle\n",
    "        model = Sequential([\n",
    "                    data_augmentation,\n",
    "                    \n",
    "                    # To rescale an input in the [0, 255] range to be in the [0, 1] range, you would pass scale=1./255.\n",
    "                    # To rescale an input in the [0, 255] range to be in the [-1, 1] range, you would pass scale=1./127.5, offset=-1.\n",
    "                    tf.keras.layers.Rescaling(1./127.5, offset=-1),\n",
    "                    model_base,\n",
    "                    GlobalAveragePooling2D(),\n",
    "                    Dense(256, activation='relu'),\n",
    "                    Dropout(0.5),\n",
    "                    Dense(NBCLASS_, activation='softmax')\n",
    "                    ])\n",
    "    \n",
    "    else:\n",
    "        # Data augmentation\n",
    "        data_augmentation = Sequential([\n",
    "            experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(224, 224, 3)),\n",
    "            experimental.preprocessing.RandomRotation(0.1),\n",
    "            experimental.preprocessing.RandomZoom(0.1),\n",
    "            # experimental.preprocessing.Rescaling(1./127.5, offset=-1.0)\n",
    "        ])\n",
    "        \n",
    "        # Récupération modèle pré-entraîné\n",
    "        model_base = VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "        for layer in model_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Définition du nouveau modèle\n",
    "        model = Sequential([\n",
    "                    data_augmentation,\n",
    "                    # To rescale an input in the [0, 255] range to be in the [0, 1] range, you would pass scale=1./255.\n",
    "                    # To rescale an input in the [0, 255] range to be in the [-1, 1] range, you would pass scale=1./127.5, offset=-1.\n",
    "                    experimental.preprocessing.Rescaling(1./127.5, offset=-1),\n",
    "                    model_base,\n",
    "                    GlobalAveragePooling2D(),\n",
    "                    Dense(256, activation='relu'),\n",
    "                    Dropout(0.5),\n",
    "                    Dense(NBCLASS_, activation='softmax')\n",
    "                    ])\n",
    "\n",
    "    \n",
    "\n",
    "    # compilation du modèle \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Création du modèle\n",
    "with tf.device('/gpu:0'): \n",
    "    model4 = create_model_fct2()\n",
    "\n",
    "# Création du callback\n",
    "model4_save_path = \"./model4_best_weights.h5\"\n",
    "checkpoint = ModelCheckpoint(model4_save_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "callbacks_list = [checkpoint, es]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/gpu:0'): \n",
    "    history4 = model4.fit(dataset_train,\n",
    "                    validation_data=dataset_val,\n",
    "                    batch_size=batch_size, epochs=50, callbacks=callbacks_list, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Score du dernier epoch\n",
    "\n",
    "loss, accuracy = model4.evaluate(dataset_train, verbose=True)\n",
    "print(\"Training Accuracy   : {:.4f}\".format(accuracy))\n",
    "print()\n",
    "loss, accuracy = model4.evaluate(dataset_val, verbose=True)\n",
    "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score de l'epoch optimal\n",
    "\n",
    "model4.load_weights(model4_save_path)\n",
    "\n",
    "loss, accuracy = model4.evaluate(dataset_val, verbose=False)\n",
    "print(\"Validation Accuracy :  {:.4f}\".format(accuracy))\n",
    "\n",
    "loss, accuracy = model4.evaluate(dataset_test, verbose=False)\n",
    "print(\"Test Accuracy       :  {:.4f}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from plot_keras_history import show_history, plot_history\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    show_history(history4)\n",
    "    plot_history(history4, path=\"standard.png\")\n",
    "    plt.close()\n",
    "except:\n",
    "    epochs_range = range(len(history4.history['loss']))\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, history4.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(epochs_range, history4.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, history4.history['loss'], label='Training Loss')\n",
    "    plt.plot(epochs_range, history4.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.argmax(model4.predict(X_test), axis=1)\n",
    "\n",
    "y_test_pred_transform = conf_mat_transform(y_test_num, y_test_pred)\n",
    "conf_mat = metrics.confusion_matrix(y_test_num, y_test_pred_transform)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat, display_labels=list_labels)\n",
    "disp.plot()\n",
    "plt.rcParams['figure.figsize']=[6,6]\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test_num, y_test_pred_transform))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
